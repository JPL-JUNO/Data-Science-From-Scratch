\chapter{Working with Data}
\section{Exploring Your Data}
After you've identified the questions you're trying to answer and have gotten your
hands on some data, you might be tempted to dive in and immediately start building
models and getting answers. But you should resist this urge. Your first step should be
to explore your data.
\subsection{Exploring One-Dimensional Data}
An obvious first step is to compute a few summary statistics. You'd like to know how
many data points you have, the smallest, the largest, the mean, and the standard deviation.

But even these don't necessarily give you a great understanding. A good next step is to
create a histogram, in which you group your data into discrete buckets and count how
many points fall into each bucket.

\subsection{Two Dimensions}
\subsection{Many Dimensions}
With many dimensions, you'd like to know how all the dimensions relate to one
another. A simple approach is to look at the \emph{correlation matrix}, in which the entry in
row $i$ and column $j$ is the correlation between the ith dimension and the jth dimension of the data.


A more visual approach (\notes{if you don't have too many dimensions}) is to make a scatterplot matrix \autoref{Scatterplot matrix} showing all the pairwise scatterplots.

\figures{Scatterplot matrix}

\section{Using NamedTuples}

One common way of representing data is using dicts. There are several reasons why this is less than ideal, however. This is a slightly inefficient representation (a dict involves some overhead), so that if you have a lot of data they'll take up more memory than they have to. For the most part, this is a
minor consideration. A larger issue is that accessing things by dict key is error-prone. Finally, while we can type-annotate uniform dictionaries, there's no helpful way to annotate dictionaries-as-data that have lots of different value
types.

As an alternative, Python includes a \href{https://docs.python.org/3/library/collections.html#collections.namedtuple}{namedtuple} (Returns a new tuple subclass named typename. ) class, which is like a tuple but with
named slots. Like regular tuples, namedtuples are immutable, which means that you can't modify
their values once they're created. (不能修改)

You'll notice that we still haven't solved the type annotation issue. We do that by using
the typed variant, NamedTuple. namedtuple子类仍然不能解决代码提示问题

\section{Dataclasses}
Dataclasses are (sort of) a mutable version of NamedTuple. (``sort of'' because
NamedTuples represent their data compactly as tuples, whereas dataclasses are regular
Python classes that simply generate some methods for you automatically.)

The syntax is very similar to NamedTuple. But instead of inheriting from a base class,
we use a decorator. The big difference is that we can modify a dataclass instance's values.
If we tried to modify a field of the NamedTuple version, we'd get an \verb|AttributeError|.

This also leaves us susceptible to the kind of errors we were hoping to avoid by not
using dicts.

\section{Cleaning and Munging}
\section{Manipulating Data}
One of the most important skills of a data scientist is \emph{manipulating data}.

\section{Rescaling}
Many techniques are sensitive to the \emph{scale} of your data. (尤其是涉及距离计算的时候)

Obviously it's a problem if changing units can change results like this. For this reason,
when dimensions aren't comparable with one another, we will sometimes rescale our
data so that each dimension has mean 0 and standard deviation 1. This effectively
gets rid of the units, converting each dimension to ``standard deviations from the
mean.''

\section{An Aside: tqdm}
Frequently we'll end up doing computations that take a long time. When you're doing such work, you'd like to know that you're making progress and how long you should
expect to wait. One way of doing this is with the tqdm library, which generates custom progress bars.

There are only a few features you need to know about.
\begin{enumerate}
    \item an iterable wrapped in \verb|tqdm.tqdm| will produce a progress bar. In this case (where we are just wrapping a call to range) you can just use \verb|tqdm.trange|.
    \item You can also set the description of the progress bar while it's running. To do that, you
          need to capture the tqdm iterator in a with statement.
    \item Using tqdm will occasionally make your code flaky—sometimes the screen redraws
          poorly, and sometimes the loop will simply hang. And if you accidentally wrap a tqdm
          loop inside another tqdm loop, strange things might happen. Typically its benefits
          outweigh these downsides, though, so we'll try to use it whenever we have slow-
          running computations.
\end{enumerate}

\section{Dimensionality Reduction}
Sometimes the ``actual'' (or useful) dimensions of the data might not correspond to the dimensions we have. When this is the case, we can use a technique called principal component analysis
(PCA) to extract one or more dimensions that capture as much of the variation in the
data as possible.

\begin{tcolorbox}
    In practice, you wouldn't use this technique on such a low-
    dimensional dataset. Dimensionality reduction is mostly useful
    when your dataset has a large number of dimensions and you want
    to find a small subset that captures most of the variation.
\end{tcolorbox}

As a first step, we'll need to translate the data so that each dimension has mean 0. If we don't do this, our techniques are likely to identify the mean itself rather than
the variation in the data.